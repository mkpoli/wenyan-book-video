import json
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Tuple

from dotenv import load_dotenv
from openai import OpenAI


MODEL_NAME = "gpt-5-nano"
API_DELAY_SECONDS = 1.0  # Small delay between batches
MAX_SENTENCES_PER_BATCH = 30
MAX_CHARS_PER_BATCH = 2000


TRANSLATION_PROMPT = """The following is requirements for a translation task. Follow these rules carefully and operate accordingly.

## Target

From: Traditional Classical Chinese (æ–‡è¨€æ–‡/æ¼¢æ–‡) written in modern era.
To: Modern or Contemporary English
Subject: Modern technical text (a introductory handbook)
Topic: Programming basics and a programming language called Wenyan (world's first Classical Chinese-styled programming language) 

## English Style
- Use dignified, reflective, refined, natural, antique-feeling, recondite, rhythmic, and occasionally poetic and philosophical phrasing suitable for a didactic text with full classical nuance.
- Strive for clarity while maintaining the philosophical rhythm and rhetorical symmetry, phonetic harmony and balance of Classical Chinese.
- Add proper and old-style, typographical English punctuations (period, comma, semicolon, colon, dash, quotation marks: ã€Œã€â†’â€œâ€, ã€ã€â†’â€˜â€™, etc.) inside the same line only according to the context.
- Output plain text only available in Unicode.

## Consistency
- Each Chinese sentence ends with ã€‚ -> one English line (no line-breaking). Keep strict 1:1 mapping: no merging, no splitting, no reordering, no omission, authentic and faithful as possible without hurting the natural flow and clarity.
- Equivalent of comma and period in English are all marked with â€œã€‚â€, so potentially two or more Chinese sentences may be mapped to one English line.
    - Xè€…ã€‚ = topic (â€œAs for Xâ€”â€, â€œâ€˜X,â€™ â€”â€, etc.)
    - Xè€…ã€‚Yä¹Ÿã€‚ = two lines: topic â†’ explanation. (["Aè€…ã€‚", "Bä¹Ÿã€‚"] -> ["A â€”", "is B"] etc.) h
    - å¤«Xè€…ã€‚â€¦â€¦ã€‚ = â€œSpeaking of/Regarding/About X,â€¦â€
- Keep all nested quotations and rhetorical questions, metaphors intact if possible.
- Use typographical punctuation (â€” , ; â€¦ â€œâ€ â€˜ â€™) where natural.

## Glossary
Use below for meaning consistency, but be flexible and accommdating, not literal word-for-word mapping, adjust depending on context.
- â€œè¨ˆé–‹â€ â†’ means â€œTable of Contentsâ€, used as â€œAs follows,â€, or â€œLet us begin.â€, can be translated as  â€œLet us unfold our explanation.â€, .
- â€œè‡³æ­¤ç•§å‚™çŸ£â€ â†’ â€œThus it is now briefly complete.â€
- After a question, â€œè€¶ã€‚â€ or â€œä¹ã€‚â€, usually there will be a follow-up answer witf â€œæ›°ã€‚â€, translate it as â€œIt is answered,â€ or a like.

### Code
- â€œç”²â€ â†’ â€œAâ€, â€œä¹™â€ â†’ â€œBâ€, â€œä¸™â€ â†’ â€œCâ€, â€œä¸â€ â†’ â€œDâ€, â€œæˆŠâ€ â†’ â€œEâ€, â€œå·±â€ â†’ â€œFâ€, â€œåºšâ€ â†’ â€œGâ€, â€œè¾›â€ â†’ â€œHâ€, â€œå£¬â€ â†’ â€œIâ€, â€œç™¸â€ â†’ â€œJâ€, etc.
- â€œæ›¸ä¹‹â€ â†’ â€œWrite it down.â€
- â€œäº‘äº‘ã€‚â€ â†’ â€œThus and thus.â€ (â€œâ€¦â€¦äº‘äº‘ã€‚â€ â†’ â€œAnd alikeâ€, â€œlike â€¦â€¦â€, â€œbeginning with â€¦â€¦â€, etc.)
- Classes:
    - â€œæ•¸â€ â†’ â€œNumbers (numerals)â€.
    - â€œè¨€â€ â†’ â€œWords (strings)â€.
    - â€œçˆ»â€ â†’ â€œYÃ¡o (booleans)â€.
    - â€œåˆ—â€ â†’ â€œLists (arrays)â€.
    - â€œç‰©â€ â†’ â€œThings (objects)â€.
    - â€œè¡“â€ â†’ â€œMeans (methods)â€.
    - â€œå¾æœ‰ä¸€è¨€ã€‚æ›°ã€â€¦â€¦ã€ã€‚åä¹‹æ›°â€¦â€¦ã€‚â€ â†’ â€œI have a word.â€ â€œIt says, â€˜â€¦â€¦â€™.â€; Name it â€˜â€¦â€¦â€™.â€
    - â€œæœ‰æ•¸ä¹ã€‚åä¹‹æ›°ã€Œâ€¦â€¦ã€â€ -> â€œThere are a number of nine.â€ â€œIt is named â€˜â€¦â€¦â€™.â€
- Loops
    - â€œå¾ªç’°â€ â†’ â€œLoopsâ€, â€œLoopingâ€
    - â€œæ†ç‚ºæ˜¯ã€‚â€ â†’ â€œConstantly do this.â€
    - â€œç‚ºæ˜¯ç™¾éã€‚â€ â†’ â€œDo this one hundred times.â€


## Output

You will receive multiple short Chinese sentences, each with a unique `id`. Return ONLY valid JSON of the form no extra text, comments, trailing commas, etc.

  {{
    "translations": [
      {{"id": "<sentence-id>", "translation": "<English line>"}},
      ...
    ]
  }}

## Examples

æ˜“æ›°ã€‚è®ŠåŒ–è€…ã€‚é€²é€€ä¹‹è±¡ä¹Ÿã€‚ä»Šç·¨ç¨‹è€…ã€‚ç½”ä¸ä»¥è®Šæ•¸ç‚ºæœ¬ã€‚è®Šæ•¸è€…ä½•ã€‚ä¸€åå‘½ä¸€ç‰©ä¹Ÿã€‚

{{
  "translations": 
    [
        {{"id": "c2-s1", "translation":"The Book of Changes says,"}},
        {{"id": "c2-s2", "translation":""Transformation â€”"}},
        {{"id": "c2-s3"," translation":""is the image of advance and retreat.""}},
        {{"id": "c2-s4", "translation":"Now, in programming,"}},
        {{"id": "c2-s5", "translation":"nothing is without variables as its foundation."}},
        {{"id": "c2-s6", "translation":""What is a variable?""}},
        {{"id": "c2-s7", "translation":""It is a name assigned to a thing.""}}
    ]
}}

ç·¨ç¨‹è€…ä½•ã€‚æ‰€ä»¥å½¹æ©Ÿå™¨ä¹Ÿã€‚æ©Ÿå™¨è€…ä½•ã€‚æ‰€ä»¥ä»£äººåŠ›ä¹Ÿã€‚ç„¶æ©Ÿå™¨ä¹‹åŠ›ä¹Ÿå»£ã€‚å…¶ç®—ä¹Ÿé€Ÿã€‚å”¯æ™ºä¸é€®ä¹Ÿã€‚æ•…æœ‰æ™ºè€…æ…è¬€é æ…®ã€‚ä¸‹ç­†åƒè¨€ã€‚å¦‚è»ä»¤ç„¶ã€‚å¦‚è—¥æ–¹ç„¶ã€‚è¬‚ä¹‹ç¨‹å¼ã€‚æ©Ÿå™¨æ—¢æ˜ä¹‹ã€‚ä¹ƒèƒ½ç‚ºäººæ‰€ä½¿ã€‚æˆ–æ¼”æ˜Ÿæ–‡ã€‚æˆ–æäº‹ç†ã€‚

{{
  "translations": 
    [
        {{"id": "c1-s1", "translation":"What is programming?"}},
        {{"id": "c1-s2", "translation":"That by which one commands machines."}},
        {{"id": "c1-s3", "translation":"What is a machine?"}},
        {{"id": "c1-s4", "translation":"That by which human labor is replaced."}},
        {{"id": "c1-s5", "translation":"Yet the power of machines is vast,"}},
        {{"id": "c1-s6", "translation":"their calculations swift,"}},
        {{"id": "c1-s7", "translation":"but their wisdom does not reach that of man."}},
        {{"id": "c1-s8", "translation":"Therefore, the wise plan with care and foresight."}},
        {{"id": "c1-s9", "translation":"They set down a thousand words,"}},
        {{"id": "c1-s10", "translation":"as if issuing military orders,"}},
        {{"id": "c1-s11", "translation":"as if prescribing medicine â€”"}},
        {{"id": "c1-s12", "translation":"this is called a program."}},
        {{"id": "c1-s13", "translation":"Once the machine comprehends it,"}},
        {{"id": "c1-s14", "translation":"it can then be made to serve mankind â€”"}},
        {{"id": "c1-s15", "translation":"to chart the movements of the stars,"}},
        {{"id": "c1-s16", "translation":"or to analyze the patterns of reason."}}
    ]
}}

## Your Task

Now translate the following sentences:

{text}
"""


def _sort_chapter_sentences_file(path: Path) -> int:
    """
    Sort key for 'c1.sentences.json' -> 1, etc.
    """
    name = path.stem.split(".")[0]  # "c1"
    num_str = name.lstrip("c")
    return int(num_str) if num_str.isdigit() else 0


def _sentence_sort_key(sent_id: str) -> int:
    """
    Sort key for sentence ids like 'c1-s245' -> 245.
    """
    if "-s" in sent_id:
        try:
            return int(sent_id.split("-s", 1)[1])
        except ValueError:
            return 0
    return 0


def _load_client() -> OpenAI:
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError(
            "OPENAI_API_KEY environment variable not set. "
            "Please set it in your .env file or environment."
        )
    return OpenAI(api_key=api_key)


def _prepare_translation_files(
    sentences_dir: Path,
    translations_dir: Path,
) -> List[Tuple[Path, Path]]:
    """
    For each `cN.sentences.json`, ensure a corresponding
    `cN.translations.json` exists, initialized with:

      { "cN-sK": { "source": "...", "translation": "" }, ... }

    Returns a list of (sentences_path, translations_path) pairs.
    """
    translations_dir.mkdir(exist_ok=True, parents=True)

    chapter_pairs: List[Tuple[Path, Path]] = []

    for sentences_path in sorted(
        sentences_dir.glob("c*.sentences.json"), key=_sort_chapter_sentences_file
    ):
        chapter_id = sentences_path.stem.split(".")[0]  # "c1"
        translations_path = translations_dir / f"{chapter_id}.translations.json"

        if not translations_path.exists():
            canon = json.loads(sentences_path.read_text(encoding="utf-8"))
            init_data: Dict[str, Dict[str, str]] = {}

            for s in canon.get("sentences", []):
                sid = s.get("id")
                src = s.get("source", "")
                if not isinstance(sid, str) or not isinstance(src, str):
                    continue
                init_data[sid] = {"source": src, "translation": ""}

            translations_path.write_text(
                json.dumps(init_data, ensure_ascii=False, indent=2) + "\n",
                encoding="utf-8",
            )
            print(f"Created {translations_path}")

        chapter_pairs.append((sentences_path, translations_path))

    print(f"Prepared {len(chapter_pairs)} sentence translation files")
    return chapter_pairs


def _build_batches_for_chapter(
    translations_data: Dict[str, Dict[str, str]],
) -> List[List[str]]:
    """
    Build batches of sentence ids that are missing translation.
    Batches are constrained by MAX_SENTENCES_PER_BATCH and MAX_CHARS_PER_BATCH.
    """
    missing_ids = [
        sid
        for sid in sorted(translations_data.keys(), key=_sentence_sort_key)
        if not translations_data.get(sid, {}).get("translation", "").strip()
    ]

    batches: List[List[str]] = []
    current: List[str] = []
    current_chars = 0

    for sid in missing_ids:
        source = translations_data[sid].get("source", "")
        length = len(source)

        if current and (
            len(current) >= MAX_SENTENCES_PER_BATCH
            or current_chars + length > MAX_CHARS_PER_BATCH
        ):
            batches.append(current)
            current = []
            current_chars = 0

        current.append(sid)
        current_chars += length

    if current:
        batches.append(current)

    return batches


def _build_text_block_for_batch(
    translations_data: Dict[str, Dict[str, str]],
    batch_ids: List[str],
) -> str:
    """
    Build the `{text}` payload inserted into TRANSLATION_PROMPT for one batch.
    """
    lines: List[str] = []
    for idx, sid in enumerate(batch_ids, start=1):
        source = translations_data[sid].get("source", "")
        lines.append(f"SENTENCE {idx}: {sid}")
        lines.append(source.strip())
        lines.append("")  # blank line between sentences
    return "\n".join(lines).strip()


def _call_translation_api(
    client: OpenAI,
    batch_ids: List[str],
    translations_data: Dict[str, Dict[str, str]],
) -> Dict[str, str]:
    """
    Call the model for one batch of sentence ids.
    Returns a mapping {sent_id: translated_line}.
    """
    text_block = _build_text_block_for_batch(translations_data, batch_ids)
    prompt = TRANSLATION_PROMPT.format(text=text_block)
    system_content = (
        "You are an expert translator specializing in Classical Chinese "
        "to English translation, particularly for technical and literary works."
    )

    # Debug: print exact prompt with separators
    print("\n" + "=" * 80)
    print("DEBUG: System Message")
    print("=" * 80)
    print(system_content)
    print("\n" + "=" * 80)
    print("DEBUG: User Prompt (Exact)")
    print("=" * 80)
    print(prompt)
    print("=" * 80 + "\n")

    print(f"  ğŸ¤– Translating {len(batch_ids)} sentence(s)...")

    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": system_content},
            {"role": "user", "content": prompt},
        ],
    )

    raw = (response.choices[0].message.content or "").strip()
    print("  ğŸ“¦ Raw response preview:")
    print(f"     {raw[:200]}..." if len(raw) > 200 else f"     {raw}")

    try:
        payload = json.loads(raw)
    except json.JSONDecodeError as exc:
        raise RuntimeError(f"Failed to parse JSON from model response: {exc}") from exc

    translations_list = payload.get("translations")
    if not isinstance(translations_list, list):
        raise RuntimeError(
            "Model response JSON does not contain a 'translations' list."
        )

    result: Dict[str, str] = {}
    for entry in translations_list:
        if not isinstance(entry, dict):
            continue
        sid = entry.get("id")
        t = entry.get("translation")
        if isinstance(sid, str) and isinstance(t, str):
            result[sid] = t.strip()

    missing = [sid for sid in batch_ids if sid not in result]
    if missing:
        raise RuntimeError(
            f"Missing translations for sentence(s): {', '.join(missing)}"
        )

    return result


def _translate_chapter(
    client: OpenAI,
    sentences_path: Path,
    translations_path: Path,
) -> None:
    """
    Translate all missing sentences in one chapter's translations file.
    """
    chapter_id = sentences_path.stem.split(".")[0]  # "c1"
    print("\n" + "=" * 80)
    print(f"Translating sentence file: {chapter_id}")
    print("=" * 80)

    translations_data: Dict[str, Dict[str, str]] = json.loads(
        translations_path.read_text(encoding="utf-8")
    )

    batches = _build_batches_for_chapter(translations_data)
    if not batches:
        print("  âœ“ No missing translations; nothing to do.")
        return

    print(
        f"  Found {sum(len(b) for b in batches)} missing sentence(s) "
        f"in {len(batches)} batch(es)."
    )

    changed = False

    try:
        for batch_idx, batch_ids in enumerate(batches, start=1):
            print(f"\n  Batch {batch_idx}/{len(batches)}: {len(batch_ids)} sentence(s)")
            try:
                batch_translations = _call_translation_api(
                    client, batch_ids, translations_data
                )
            except Exception as exc:
                print(f"  âŒ Error translating batch {batch_idx}: {exc}")
                # Save partial progress before breaking
                if changed:
                    translations_path.write_text(
                        json.dumps(translations_data, ensure_ascii=False, indent=2)
                        + "\n",
                        encoding="utf-8",
                    )
                    print(f"  âœ“ Saved partial progress: {translations_path.name}")
                break

            for sid, eng in batch_translations.items():
                entry = translations_data.get(sid) or {}
                entry["translation"] = eng
                translations_data[sid] = entry
                preview = eng[:60] + ("..." if len(eng) > 60 else "")
                print(f"    ğŸ’¾ {sid}: {preview}")
                changed = True

            # Save after each batch so progress isn't lost on interruption
            if changed:
                translations_path.write_text(
                    json.dumps(translations_data, ensure_ascii=False, indent=2) + "\n",
                    encoding="utf-8",
                )
                print(f"  âœ“ Saved progress after batch {batch_idx}")

            print(f"  â³ Waiting {API_DELAY_SECONDS:.1f}s before next batch...")
            time.sleep(API_DELAY_SECONDS)
    except KeyboardInterrupt:
        # User interrupted (Ctrl+C); save what we have
        if changed:
            translations_path.write_text(
                json.dumps(translations_data, ensure_ascii=False, indent=2) + "\n",
                encoding="utf-8",
            )
            print(f"\n  âœ“ Saved partial progress before exit: {translations_path.name}")
        print("\n  â†¯ Interrupted by user; stopping translation.")
        raise SystemExit(0)

    if changed:
        print(f"\n  âœ“ Completed all batches for {translations_path.name}")
    else:
        print("\n  âœ“ No changes made for this chapter.")


def main() -> None:
    root = Path(__file__).resolve().parents[1]  # processor/ -> project root
    sentences_dir = (root / "renderer" / "public" / "sentences").resolve()
    translations_dir = (root / "renderer" / "public" / "translations").resolve()

    if not sentences_dir.exists():
        raise SystemExit(f"Sentences directory not found: {sentences_dir}")

    client = _load_client()
    chapter_pairs = _prepare_translation_files(sentences_dir, translations_dir)

    wanted: List[str] = []
    if len(sys.argv) > 1:
        wanted = list(sys.argv[1:])

    for sentences_path, translations_path in chapter_pairs:
        chapter_id = sentences_path.stem.split(".")[0]  # "c1"
        if wanted and chapter_id not in wanted:
            continue
        _translate_chapter(client, sentences_path, translations_path)

    print("\nAll done.")


if __name__ == "__main__":
    main()
